providers:
  google:
    api_key_env: GEMINI_API_KEY
    models:
      gemini-2.5-pro:
        aliases: [gemini]
        max_tokens: 32768  # Context window
        max_completion_tokens: 8192
        timeout: 600
        retry_attempts: 3
        capabilities: ["text"]

  openai:
    api_key_env: OPENAI_API_KEY
    models:
      gpt-5:
        aliases: [gpt5]
        max_tokens: 32768  # Context window
        max_completion_tokens: 8192
        timeout: 600
        retry_attempts: 3
        capabilities: ["text"]

  together:
    api_key_env: TOGETHER_API_KEY
    base_url: https://api.together.xyz/v1
    models:
      meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo:
        aliases: [llama, llama-3.1-70b, llama-70b]
        max_tokens: 8192
        max_completion_tokens: 4096
        timeout: 300
        retry_attempts: 3
        capabilities: ["text"]
      meta-llama/Llama-3.3-70B-Instruct-Turbo:
        aliases: [llama-3.3, llama-3.3-70b]
        max_tokens: 8192
        max_completion_tokens: 4096
        timeout: 300
        retry_attempts: 3
        capabilities: ["text"]
      deepseek-ai/DeepSeek-R1:
        aliases: [deepseek, deepseek-r1]
        max_tokens: 8192
        max_completion_tokens: 4096
        timeout: 400
        retry_attempts: 3
        capabilities: ["text"]
      Qwen/Qwen2.5-72B-Instruct-Turbo:
        aliases: [qwen, qwen-72b, qwen2.5]
        max_tokens: 8192
        max_completion_tokens: 4096
        timeout: 300
        retry_attempts: 3
        capabilities: ["text"]
      # DISABLED: mistralai/Mistral-Large-2411 - Model not available on Together AI (404 error)
      # mistralai/Mistral-Large-2411:
      #   aliases: [mistral, mistral-large]
      #   max_tokens: 8192
      #   max_completion_tokens: 4096
      #   timeout: 350
      #   retry_attempts: 3
      #   capabilities: ["text"]

      # DISABLED: nvidia/Llama-3.1-Nemotron-70B-Instruct-HF - Requires dedicated endpoint (non-serverless)
      # nvidia/Llama-3.1-Nemotron-70B-Instruct-HF:
      #   aliases: [nemotron, nemotron-70b]
      #   max_tokens: 8192
      #   max_completion_tokens: 4096
      #   timeout: 300
      #   retry_attempts: 3
      #   capabilities: ["text"]

  xai:
    api_key_env: XAI_API_KEY
    models:
      grok-4-0709:
        aliases: [grok, grok-4]
        max_tokens: 16384
        max_completion_tokens: 8192
        timeout: 500
        retry_attempts: 3
        capabilities: ["text"]

defaults:
  models: [gemini-2.5-pro, gpt-5, grok-4-0709]
  output_dir: ./fiedler_output
